{% set NODE_IXS = range(1, (RABBIT_CLUSTER_NODE_COUNT | int) + 1) -%}

services:
  loadbalancer:
    image: haproxy:3.2
    deploy:
      # https://discourse.haproxy.org/t/haproxy-high-availability-configuration/11983
      replicas: ${RABBIT_LB_REPLICAS}
      # necessary to preserve client ip
      # otherwise we see overlay network lb ip
      # (rabbitmq management dashboard connection section)
      endpoint_mode: dnsrr
    # healthcheck: https://github.com/haproxy/haproxy/issues/3091
    networks:
      - rabbit
    configs:
      - source: haproxy.cfg
        target: /usr/local/etc/haproxy/haproxy.cfg

{% for ix in NODE_IXS %}
  rabbit0{{ ix }}:
    image: itisfoundation/rabbitmq:4.1.2-management
    init: true
    # https://docs.docker.com/reference/cli/docker/service/create/#create-services-using-templates
    hostname: {% raw %}"{{.Service.Name}}"{% endraw %}
    deploy:
      placement:
        constraints:
          - node.labels.rabbit0{{ ix }} == true
    environment:
      # https://www.rabbitmq.com/docs/configure#supported-environment-variables
      RABBITMQ_DEFAULT_USER: ${RABBIT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBIT_PASSWORD}
      RABBITMQ_NODENAME: {% raw %}"rabbit@{{.Service.Name}}"{% endraw %}
      RABBITMQ_NODE_PORT: ${RABBIT_PORT}
    # https://docs.docker.com/reference/compose-file/services/#long-syntax-5
    # https://hub.docker.com/_/rabbitmq#erlang-cookie
    secrets:
      # https://github.com/docker-library/rabbitmq/issues/279
      - source: rabbit_erlang_cookie
        target: /var/lib/rabbitmq/.erlang.cookie
        mode: 0600
        # as long as "default" user is used (no user explicitly specified)
        uid: "999"
        gid: "999"
    configs:
      - source: rabbitmq.conf
        target: /etc/rabbitmq/rabbitmq.conf
        mode: 0600
        uid: "999"
        gid: "999"
    volumes:
      - rabbit0{{ ix }}_data:/var/lib/rabbitmq
    # TODO: sync with existing rabbit attached networks
    networks:
      - rabbit
    # TODO: consider another healthcheck (e.g. check kubernetes operator)
    healthcheck:
      # see https://hub.docker.com/_/rabbitmq#healthlivenessreadiness-checking
      # https://www.rabbitmq.com/docs/clustering#restarting-readiness-probes
      # we must have a healthcheck that does not require node to be fully booted (i.e. joined a cluster)
      # because it creates a deadlock: docker swarm will not route to the node until it is healthy
      # node is not healthy until it is part of a cluster (other node can talk to it)
      test: rabbitmq-diagnostics ping
      interval: 60s
      timeout: 10s
      retries: 2
      start_period: 30s
      start_interval: 10s
{% endfor %}

  subscriber:
    image: python:3.11
    command: sh -c "pip install pika && python /app/sub.py"
    environment:
      - RABBIT_HOSTS=rabbit_loadbalancer
      - RABBIT_USER=${RABBIT_USER}
      - RABBIT_PASS=${RABBIT_PASSWORD}
    networks:
      - rabbit
    volumes:
      - ./test/sub.py:/app/sub.py

  publisher:
    image: python:3.11
    command: sh -c "pip install pika && python /app/pub.py"
    environment:
      - RABBIT_HOSTS=rabbit_loadbalancer
      - RABBIT_USER=${RABBIT_USER}
      - RABBIT_PASS=${RABBIT_PASSWORD}
    networks:
      - rabbit
    volumes:
      - ./test/pub.py:/app/pub.py

volumes:
{% for ix in NODE_IXS %}
  rabbit0{{ ix }}_data:
    name: ${STACK_NAME}0{{ ix }}_data
{%- endfor %}

networks:
  rabbit:
    name: ${RABBIT_NETWORK}
    external: true

configs:
  rabbitmq.conf:
    # no rolling update since it requires full cluster restart
    file: ./rabbitmq.conf
  haproxy.cfg:
    file: ./haproxy.cfg
    name: ${STACK_NAME}_haproxy_conf_{{ "./haproxy.cfg" | sha256file | substring(0,10) }}

secrets:
  rabbit_erlang_cookie:
    # no rolling update since it requires full cluster restart
    name: ${STACK_NAME}_erlang_cookie
    file: ./erlang.cookie.secret
