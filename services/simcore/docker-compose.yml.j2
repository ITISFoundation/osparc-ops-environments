services:
  clusters-keeper:
    networks:
      - monitored
    deploy:
      replicas: 0
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        # Instruction how to measure resources: https://github.com/ITISFoundation/osparc-ops-environments/issues/330#issuecomment-1746359262
        # for limits cpu / memory see the max usage and increase it by some percent or multiple by 2 depending on the criticality
        # for reservations cpu / memory see the min usage
        limits:
          memory: 300M # Determined from prometheus cadvisor actual usage on master, which was <100M
          cpus: '0.5' # For now: same as autoscaling service
        reservations:
          memory: 100M # Determined from prometheus cadvisor actual usage on master, which was <100M
          cpus: '0.1' # For now: same as autoscaling service
      placement:
        constraints:
          - node.labels.simcore==true

  autoscaling:
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "128M"
        limits:
          cpus: "0.5"
          memory: "512M"

  agent:
    networks:
      - monitored
    hostname: "{% raw %}{{.Node.Hostname}}-{{.Service.Name}}{% endraw %}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - LOGLEVEL=WARNING
      - AGENT_VOLUMES_CLEANUP_TARGET_SWARM_STACK_NAME=${AGENT_VOLUMES_CLEANUP_TARGET_SWARM_STACK_NAME}
    deploy:
      update_config:
        parallelism: 2
        order: stop-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.dynamicsidecar == true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "1.0"
          memory: "2G"
    extra_hosts: []

  api-server:
    networks:
      - public
      - monitored
    deploy:
      replicas: 2
      labels:
        # NOTE: apiserver does not need sslheader since there is no socket.io
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.middlewares=${SWARM_STACK_NAME}_gzip@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.service=${SWARM_STACK_NAME}_api-server
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.rule=PathPrefix(`/dev/`) || PathPrefix(`/doc/`) || PathPrefix(`/doc`)
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.entrypoints=simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.priority=6
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "128M"
        limits:
          cpus: "1.0"
          memory: "600M"
    extra_hosts: []

  catalog:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_CATALOG_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.3"
          memory: "128M"
        limits:
          cpus: "1.0"
          memory: "512M"

  static-webserver:
    deploy:
      replicas: 2
      labels:
        # Handle freshping service and route it to the faster static webserver.
        - traefik.http.middlewares.${SWARM_STACK_NAME}_static_webserver_prefix.addprefix.prefix=/osparc
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.rule=HeaderRegexp(`User-Agent`, `.*(FreshpingBot).*`)
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.service=${SWARM_STACK_NAME}_static_webserver_freshping
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_freshping.loadbalancer.server.port=8000
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.priority=12 # High number means high priority
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.middlewares=${SWARM_STACK_NAME}_gzip@swarm,${SWARM_STACK_NAME}_static_webserver_retry,${SWARM_STACK_NAME}_static_webserver_prefix
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "0.5"
          memory: "128M"

  invitations:
    networks:
      - monitored
    environment:
      - INVITATIONS_LOGLEVEL=${INVITATIONS_LOGLEVEL}
    deploy:
      labels:
        # internal traefik
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # NOTE: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations.rule=(${DEPLOYMENT_FQDNS_CAPTURE_INVITATIONS})
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations.entrypoints=http
        - traefik.http.services.${SWARM_STACK_NAME}_invitations.loadbalancer.server.port=8000
        - traefik.http.services.${SWARM_STACK_NAME}_invitations.loadbalancer.healthcheck.path=/
        - traefik.http.services.${SWARM_STACK_NAME}_invitations.loadbalancer.healthcheck.interval=2000ms
        - traefik.http.services.${SWARM_STACK_NAME}_invitations.loadbalancer.healthcheck.timeout=1000ms
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.rule=(${DEPLOYMENT_FQDNS_CAPTURE_INVITATIONS}) && PathPrefix(`/dev/doc`)
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.entrypoints=http
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_invitations_swagger_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_invitations_swagger_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "0.2"
          memory: "256M"

  webserver:
    networks:
      - public
      - monitored
    environment:
      - DIAGNOSTICS_MAX_AVG_LATENCY=10
      - WEBSERVER_STATIC_MODULE_STATIC_WEB_SERVER_URL=http://${PREFIX_STACK_NAME}_static-webserver:8000
      # temporaries for helping to debug issues with responsivity
      - PYTHONTRACEMALLOC=1
      - AIODEBUG_SLOW_DURATION_SECS=0.5
      - GUNICORN_CMD_ARGS=--timeout=90
      - PROJECTS_MAX_COPY_SIZE_BYTES=${PROJECTS_MAX_COPY_SIZE_BYTES}
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
      - WEBSERVER_ANNOUNCEMENTS=${WEBSERVER_ANNOUNCEMENTS}
    deploy:
      labels:
        # ssl header necessary so that socket.io upgrades correctly from polling to websocket mode. the middleware must be attached to the right connection.
        # NOTE: traefik does not like - in the sslheader middleware, so we override it here
        # NOTE: in deploy mode with SSL they must be set to https!
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_sslheader.headers.customrequestheaders.X-Forwarded-Proto=https
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.service=${SWARM_STACK_NAME}_webserver
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.rule=PathPrefix(`/dev/`) || PathPrefix(`/doc/`) || PathPrefix(`/doc`)
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.priority=6
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_webserver_swagger_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_webserver_swagger_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      update_config: &webserver_update_config
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy: &webserver_restart_policy
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      replicas: 3
      placement:
        constraints:
          - node.labels.simcore==true
      resources: &webserver_resources
        reservations:
          cpus: "0.1"
          memory: "512M"
        limits:
          cpus: "4"
          memory: "2G"
    extra_hosts: []

  wb-api-server:
    networks:
      - monitored
    deploy:
      update_config:
        <<: *webserver_update_config
      restart_policy:
        <<: *webserver_restart_policy
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        <<: *webserver_resources
    extra_hosts: []

  wb-db-event-listener:
    hostname: "{% raw %}{{.Service.Name}}{% endraw %}"
    environment:
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
    networks:
      - default
      - monitored
    deploy:
      # NOTE: https://github.com/ITISFoundation/osparc-simcore/pull/4286
      # NOTE: this MUSTN'T change, or weird things might happen
      # this will stay until all legacy dynamic services are gone.
      replicas: 1
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore == true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "0.5"
          memory: "512M"

  wb-garbage-collector:
    environment:
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
    networks:
      - default
      - interactive_services_subnet
      - monitored
    hostname: "{% raw %}{{.Service.Name}}{% endraw %}"
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.role==manager
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1.0"
          memory: "512M"

  storage:
    environment:
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - STORAGE_DEFAULT_PRESIGNED_LINK_EXPIRATION_SECONDS=${STORAGE_DEFAULT_PRESIGNED_LINK_EXPIRATION_SECONDS}
      - STORAGE_CLEANER_INTERVAL_S=${STORAGE_CLEANER_INTERVAL_S}
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_STORAGE_REPLICAS}
      labels:
        # internal traefik
        - traefik.enable=true
        - traefik.swarm.network=${SWARM_STACK_NAME}_default
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.rule=${DEPLOYMENT_FQDNS_CAPTURE_STORAGE}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.entrypoints=http
        - traefik.http.services.${SWARM_STACK_NAME}_storage.loadbalancer.server.port=8080
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_storage_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_storage_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          memory: "3G"

  sto-worker:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_STO_WORKER_REPLICAS}
      update_config:
        parallelism: 1
        order: start-first
        failure_action: rollback
        delay: 10s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "350M"
        limits:
          cpus: "1"
          memory: "700M"

  sto-worker-cpu-bound:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_STO_WORKER_CPU_BOUND_REPLICAS}
      update_config:
        parallelism: 1
        order: start-first
        failure_action: rollback
        delay: 10s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "200M"
        limits:
          cpus: "1"
          memory: "1G"

  director:
    # Certificate necessary for local deploiement only
    #secrets:
    #- source: rootca.crt
    #target: /usr/local/share/ca-certificates/osparc.crt
    environment:
      - SIMCORE_SERVICES_NETWORK_NAME=${SWARM_STACK_NAME}_interactive_services_subnet
      - REGISTRY_SSL=${REGISTRY_SSL}
      # needed to pass the self-signed certificate to the spawned services
      #- DIRECTOR_SELF_SIGNED_SSL_FILENAME=/usr/local/share/ca-certificates/osparc.crt
      # - DIRECTOR_SELF_SIGNED_SSL_SECRET_ID=some_id
      #- DIRECTOR_SELF_SIGNED_SSL_SECRET_NAME=rootca.crt
      #- SSL_CERT_FILE=/usr/local/share/ca-certificates/osparc.crt
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_DIRECTOR_V0_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "0.5"
          memory: "1G"

  director-v2:
    environment:
      - SIMCORE_SERVICES_NETWORK_NAME=${SWARM_STACK_NAME}_interactive_services_subnet
      - REGISTRY_SSL=${REGISTRY_SSL}
      - DIRECTOR_V2_DEV_FEATURES_ENABLED=${DIRECTOR_V2_DEV_FEATURES_ENABLED}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_SECURE=${S3_SECURE}
      - R_CLONE_PROVIDER=${R_CLONE_PROVIDER}
      - DYNAMIC_SIDECAR_LOG_LEVEL=${DYNAMIC_SIDECAR_LOG_LEVEL}
      - DIRECTOR_V2_LOGLEVEL=${DIRECTOR_V2_LOGLEVEL}
      # needed to pass the self-signed certificate to the spawned services
      #- DIRECTOR_SELF_SIGNED_SSL_FILENAME=/usr/local/share/ca-certificates/osparc.crt
      # - DIRECTOR_SELF_SIGNED_SSL_SECRET_ID=some_id
      #- DIRECTOR_SELF_SIGNED_SSL_SECRET_NAME=rootca.crt
      #- SSL_CERT_FILE=/usr/local/share/ca-certificates/osparc.crt
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: stop-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          memory: "1G"

  dask-sidecar:
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.dasksidecar==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          # memory: "16G"  # YH & SAN --> we should not limit dask sidecars | Jan 29 2024

  dask-scheduler:
    networks:
      - public
      - monitored
    deploy:
      replicas: ${SIMCORE_DASK_SCHEDULER_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      labels:
        - traefik.enable=true
        - traefik.swarm.network=${PUBLIC_NETWORK}
        - traefik.http.services.${PREFIX_STACK_NAME}_dask_scheduler.loadbalancer.server.port=8787
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/${PREFIX_STACK_NAME}_dask`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.tls=true
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_dask_scheduler_replace_regex.replacepathregex.regex=^/${PREFIX_STACK_NAME}_dask/(.*)$$
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_dask_scheduler_replace_regex.replacepathregex.replacement=/$${1}
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.middlewares=${PREFIX_STACK_NAME}_dask_scheduler_replace_regex@swarm, ops_gzip@swarm, ops_auth@swarm
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 128M
          cpus: '0.1'

  datcore-adapter:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_DATCORE_ADAPTER_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.2'
        reservations:
          memory: 128M
          cpus: '0.1'

  efs-guardian:
    hostname: "{% raw %}{{.Service.Name}}{% endraw %}"
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_EFS_GUARDIAN_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

  migration:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 16M
          cpus: '0.1'
      placement:
        constraints:
          - node.labels.simcore==true

  rabbit:
    networks:
      - monitored
      - public
    volumes:
      - rabbit_data:/var/lib/rabbitmq
    deploy:
      replicas: ${RABBIT_SELF_HOSTED_REPLICAS}
      labels:
        - traefik.enable=true
        - traefik.swarm.network=${PUBLIC_NETWORK}
        - traefik.http.services.${PREFIX_STACK_NAME}_rabbit_console.loadbalancer.server.port=15672
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit_console.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/${PREFIX_STACK_NAME}_rabbit`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit_console.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit_console.tls=true
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_rabbit_console_replace_regex.replacepathregex.regex=^/${PREFIX_STACK_NAME}_rabbit/(.*)$$
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_rabbit_console_replace_regex.replacepathregex.replacement=/$${1}
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit_console.middlewares=${PREFIX_STACK_NAME}_rabbit_console_replace_regex@swarm, ops_gzip@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.rabbit==true
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 256M
          cpus: '0.1'

  redis:
    networks:
      - monitored
    deploy:
      replicas: ${REDIS_SELF_HOSTED_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.redis==true
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 32M
          cpus: '0.1'

  resource-usage-tracker:
    networks:
      - monitored
      - public
    hostname: "{% raw %}{{.Service.Name}}{% endraw %}"
    deploy:
      # NOTE: https://github.com/ITISFoundation/osparc-simcore/pull/4286
      # NOTE: this MUSTN'T change, or weird things might happen
      # this will stay until all legacy dynamic services are gone.
      replicas: ${RESOURCE_USAGE_TRACKER_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

  postgres:
    networks:
      - monitored
      - public
    deploy:
      labels:
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.swarm.network=${PUBLIC_NETWORK}
        - traefik.tcp.services.${SWARM_STACK_NAME}_postgres.loadBalancer.server.port=5432
        - traefik.tcp.routers.postgres.service=${SWARM_STACK_NAME}_postgres
        - traefik.tcp.routers.postgres.entrypoints=postgres
        - traefik.tcp.routers.postgres.tls=false
        - traefik.tcp.routers.postgres.rule=HostSNI(`*`)
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.role==manager
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 1.5G
          # cpus: '0.1'  # tmp fix due to lack of resources on master | YH Dec 2023

  traefik:
    networks:
      - monitored
      - public
    deploy:
      replicas: 2
      labels:
        # Prometheus
        - prometheus-job=traefik_simcore
        - prometheus-port=8082
        # external traefik
        - traefik.enable=true
        - traefik.swarm.network=${PUBLIC_NETWORK}
        # oSparc web
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.service=${SWARM_STACK_NAME}_simcore_http
        # Note: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.rule=((${DEPLOYMENT_FQDNS_CAPTURE_TRAEFIK_RULE_CATCHALL}) && PathPrefix(`/`)) || ( (PathPrefix(`/dashboard`) || PathPrefix(`/api`) || PathPrefix(`/doc`) ) && Host(`traefikdashboard.${MACHINE_FQDN}`))
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.priority=3
        # oSparc publicAPI
        # Note: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.rule=(${DEPLOYMENT_API_DOMAIN_CAPTURE_TRAEFIK_RULE}) && PathPrefix(`/`)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.entrypoints=https
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api.loadbalancer.server.port=10081
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.middlewares=ops_gzip@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.service=${SWARM_STACK_NAME}_simcore_api
        # oSparc non rate limited webAPI for testing
        - traefik.http.services.${SWARM_STACK_NAME}_testing_simcore_http.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.service=${SWARM_STACK_NAME}_testing_simcore_http
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.rule=(${DEPLOYMENT_FQDNS_TESTING_CAPTURE_TRAEFIK_RULE})
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_auth@swarm, ops_whitelist_ips@swarm
        # oSparc non rate limited publicAPI for testing
        - traefik.http.services.${SWARM_STACK_NAME}_testing_simcore_api.loadbalancer.server.port=10081
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.service=${SWARM_STACK_NAME}_testing_simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.rule=(${DEPLOYMENT_API_DOMAIN_TESTING_CAPTURE_TRAEFIK_RULE})
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_auth@swarm, ops_whitelist_ips@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.traefik==true
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 128M
          cpus: '0.1'

  # use to define fallback routes for simcore traefik
  # if docker healthcheck fails, simcore traefik configurarion is
  # removed from ops traeifik https://github.com/traefik/traefik/issues/7842
  #
  # use fallback routes to return proper 503 (instead of 404)
  # this service must be running at all times
  ops-traefik-configuration-placeholder:
    image: busybox:1.35.0
    command: sleep infinity
    networks:
      - public
    deploy:
      replicas: ${OPS_TRAEFIK_CONFIGURATION_PLACEHOLDER_REPLICAS}
      placement:
        constraints:
          - node.labels.traefik==true
      resources:
        limits:
          memory: 16M
          cpus: '0.1'
        reservations:
          memory: 8M
          cpus: '0.1'

      labels:
        # external traefik
        - traefik.enable=true

        ### oSparc web (fallback low priority rule)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.service=${SWARM_STACK_NAME}_simcore_http_fallback
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.rule=((${DEPLOYMENT_FQDNS_CAPTURE_TRAEFIK_RULE_CATCHALL}) && PathPrefix(`/`)) || ( (PathPrefix(`/dashboard`) || PathPrefix(`/api`) || PathPrefix(`/doc`) ) && Host(`traefikdashboard.${MACHINE_FQDN}`))
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http_fallback.priority=1
        # always return 503
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http_fallback.loadbalancer.server.port=0
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http_fallback.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http_fallback.loadbalancer.healthcheck.timeout=1ms

        ### oSparc publicAPI (fallback low priority rule)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.rule=(${DEPLOYMENT_API_DOMAIN_CAPTURE_TRAEFIK_RULE}) && PathPrefix(`/`)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.priority=1
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.middlewares=ops_gzip@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api_fallback.service=${SWARM_STACK_NAME}_simcore_api_fallback
        # always return 503
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api_fallback.loadbalancer.server.port=0
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api_fallback.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api_fallback.loadbalancer.healthcheck.timeout=1ms
    healthcheck:
      test: command -v sleep
      interval: 10s
      timeout: 1s
      start_period: 1s
      retries: 3

  traefik-configuration-placeholder: # simcore traefik with `io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}` label
    image: busybox:1.35.0
    command: sleep infinity
    networks:
      - default
    deploy:
      replicas: ${SIMCORE_TRAEFIK_CONFIGURATION_PLACEHOLDER_REPLICAS}
      labels:
        # route to internal traefik
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}

        # traefik UI
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.service=api@internal
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.rule=(PathPrefix(`/dashboard`) || PathPrefix(`/api`) ) && Host(`traefikdashboard.${MACHINE_FQDN}`)
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.middlewares=${SWARM_STACK_NAME}_auth@swarm, ${SWARM_STACK_NAME}_whitelist_ips@swarm
        - traefik.http.services.${SWARM_STACK_NAME}_traefik_api.loadbalancer.server.port=8080

        # Middlewares
        # basic authentication
        - traefik.http.middlewares.${SWARM_STACK_NAME}_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        # OPS IP Whitelist
        - traefik.http.middlewares.${SWARM_STACK_NAME}_whitelist_ips.ipallowlist.sourcerange=${TRAEFIK_IPWHITELIST_SOURCERANGE}

        ### Fallback for invitations
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_fallback.rule=${DEPLOYMENT_FQDNS_CAPTURE_INVITATIONS}
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_fallback.service=${SWARM_STACK_NAME}_invitations_fallback
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_fallback.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_fallback.priority=1
        # always fail and return 503 via unhealthy loadbalancer healthcheck
        - traefik.http.services.${SWARM_STACK_NAME}_invitations_fallback.loadbalancer.server.port=0
        - traefik.http.services.${SWARM_STACK_NAME}_invitations_fallback.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_invitations_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_invitations_fallback.loadbalancer.healthcheck.timeout=1ms

      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.traefik==true
      resources:
        limits:
          memory: 16M
          cpus: '0.1'
        reservations:
          memory: 8M
          cpus: '0.1'

  whoami:
    image: "containous/whoami:v1.5.0"
    networks:
      - default
    # NOTE: this service allows better understanding of how the host gets forwarded inside the simcore stack
    deploy:
      labels:
        # internal traefik
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # basic authentication
        - traefik.http.middlewares.${SWARM_STACK_NAME}_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        # whoami
        - traefik.enable=true
        - traefik.http.services.${SWARM_STACK_NAME}_whoami.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.rule=PathPrefix(`/whoami`)
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.priority=6
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.middlewares=${SWARM_STACK_NAME}_auth@swarm,${SWARM_STACK_NAME}_gzip@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.ops==true
      resources:
        limits:
          memory: 16M
          cpus: '0.1'
        reservations:
          memory: 8M
          cpus: '0.1'

  payments:
    deploy:
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.1'
    networks:
      - appmotion
      - monitored

  dynamic-schdlr:
    networks:
      - public
      - monitored
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 500M
          cpus: '1.000'
        reservations:
          memory: 50M
          cpus: '0.1'
      labels:
        - traefik.enable=true
        - traefik.swarm.network=${PUBLIC_NETWORK}
        # dynamic-scheduler service
        - traefik.http.services.${PREFIX_STACK_NAME}_dynamic_scheduler.loadbalancer.server.port=8000
        - traefik.http.services.${PREFIX_STACK_NAME}_dynamic_scheduler.loadbalancer.sticky.cookie=true
        - traefik.http.services.${PREFIX_STACK_NAME}_dynamic_scheduler.loadbalancer.sticky.cookie.name=sticky_session
        # dynamic-scheduler GUI Router
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/dynamic-scheduler`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler.tls=true
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler.middlewares=ops_gzip@swarm, ops_auth@swarm
        # dynamic-scheduler API Router
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler_api.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/dynamic-scheduler/v1`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler_api.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler_api.tls=true
        - traefik.http.middlewares.dynamic_scheduler_api_replace_regex.replacepathregex.regex=^/dynamic-scheduler/v1(.*)$$
        - traefik.http.middlewares.dynamic_scheduler_api_replace_regex.replacepathregex.replacement=/v1$${1}
        - traefik.http.routers.${PREFIX_STACK_NAME}_dynamic_scheduler_api.middlewares=ops_gzip@swarm, ops_auth@swarm, dynamic_scheduler_api_replace_regex

  notifications:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_NOTIFICATIONS_REPLICAS}
      placement:
        constraints:
          - node.labels.simcore==true
      update_config:
        parallelism: 1
        order: start-first
        failure_action: rollback
        delay: 10s
      resources:
        limits:
          memory: 500M
          cpus: '0.5'
        reservations:
          memory: 50M
          cpus: '0.1'

  docker-api-proxy:
    networks:
      - monitored
    deploy:
      mode: global
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      placement:
        constraints:
          - node.role==manager
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "0.5"
          memory: "512M"

volumes:
  rabbit_data:
    name: ${SWARM_STACK_NAME}_rabbit_data

networks:
  public:
    external: true
    name: ${OPS_PUBLIC_NETWORK}
  monitored:
    external: true
    name: ${OPS_MONITORED_NETWORK}
  appmotion:
    external: true
    name: ${OPS_APPMOTION_NETWORK}
  storage_subnet:
    attachable: true
    name: ${SWARM_STACK_NAME}_storage_subnet
  computational_services_subnet:
    name: ${SWARM_STACK_NAME}_computational_services_subnet
    attachable: true
  interactive_services_subnet:
    name: ${SWARM_STACK_NAME}_interactive_services_subnet
    external: true

secrets:
  dask_tls_key:
    file: ./assets/dask-certificates/dask-key.pem
    name: ${SWARM_STACK_NAME}_dask_tls_key_{{ "./assets/dask-certificates/dask-key.pem" | sha256file | substring(0,10) }}
  dask_tls_cert:
    file: ./assets/dask-certificates/dask-cert.pem
    name: ${SWARM_STACK_NAME}_dask_tls_cert_{{ "./assets/dask-certificates/dask-cert.pem" | sha256file | substring(0,10) }}
