services:
  clusters-keeper:
    networks:
      - monitored
    deploy:
      replicas: 0
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        # Instruction how to measure resources: https://github.com/ITISFoundation/osparc-ops-environments/issues/330#issuecomment-1746359262
        # for limits cpu / memory see the max usage and increase it by some percent or multiple by 2 depending on the criticality
        # for reservations cpu / memory see the min usage
        limits:
          memory: 300M # Determined from prometheus cadvisor actual usage on master, which was <100M
          cpus: '0.5' # For now: same as autoscaling service
        reservations:
          memory: 100M # Determined from prometheus cadvisor actual usage on master, which was <100M
          cpus: '0.1' # For now: same as autoscaling service
      placement:
        constraints:
          - node.labels.simcore==true

  autoscaling:
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "128M"
        limits:
          cpus: "0.5"
          memory: "512M"

  agent:
    networks:
      - monitored
    hostname: "{{.Node.Hostname}}-{{.Service.Name}}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - LOGLEVEL=WARNING
      - AGENT_VOLUMES_CLEANUP_TARGET_SWARM_STACK_NAME=${AGENT_VOLUMES_CLEANUP_TARGET_SWARM_STACK_NAME}
    deploy:
      update_config:
        parallelism: 2
        order: stop-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.dynamicsidecar == true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "1.0"
          memory: "256M"
    extra_hosts: []

  api-server:
    networks:
      - public
      - monitored
    deploy:
      replicas: 2
      labels:
        # NOTE: apiserver does not need sslheader since there is no socket.io
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.middlewares=${SWARM_STACK_NAME}_gzip@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.service=${SWARM_STACK_NAME}_api-server
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.rule=PathPrefix(`/dev/`)
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.entrypoints=simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_apiserver_swagger.priority=2
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "128M"
        limits:
          cpus: "1.0"
          memory: "600M"
    extra_hosts: []

  catalog:
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_CATALOG_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "128M"
        limits:
          cpus: "0.5"
          memory: "512M"

  static-webserver:
    deploy:
      replicas: 2
      labels:
        # Handle freshping service and route it to the faster static webserver.
        - traefik.http.middlewares.${SWARM_STACK_NAME}_static_webserver_prefix.addprefix.prefix=/osparc
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.rule=HeaderRegexp(`User-Agent`, `.*(FreshpingBot).*`)
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.service=${SWARM_STACK_NAME}_static_webserver_freshping
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_freshping.loadbalancer.server.port=8000
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.priority=10 # High number means high priority
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_freshping.middlewares=${SWARM_STACK_NAME}_gzip@swarm,${SWARM_STACK_NAME}_static_webserver_retry,${SWARM_STACK_NAME}_static_webserver_prefix
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "0.5"
          memory: "128M"

  invitations:
    networks:
      - monitored
    environment:
      - INVITATIONS_LOGLEVEL=${INVITATIONS_LOGLEVEL}
    deploy:
      labels:
        # internal traefik
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations.rule=(${DEPLOYMENT_FQDNS_CAPTURE_INVITATIONS})
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations.entrypoints=http
        - traefik.http.services.${SWARM_STACK_NAME}_invitations.loadbalancer.server.port=8000
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.rule=(${DEPLOYMENT_FQDNS_CAPTURE_INVITATIONS}) && PathPrefix(`/dev/doc`)
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.entrypoints=http
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_invitations_swagger_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_invitations_swagger.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_invitations_swagger_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "64M"
        limits:
          cpus: "0.2"
          memory: "256M"

  webserver:
    networks:
      - public
      - monitored
    environment:
      - DIAGNOSTICS_MAX_AVG_LATENCY=10
      - WEBSERVER_STATIC_MODULE_STATIC_WEB_SERVER_URL=http://${PREFIX_STACK_NAME}_static-webserver:8000
      # temporaries for helping to debug issues with responsivity
      - PYTHONTRACEMALLOC=1
      - AIODEBUG_SLOW_DURATION_SECS=0.5
      - GUNICORN_CMD_ARGS=--timeout=90
      - PROJECTS_MAX_COPY_SIZE_BYTES=${PROJECTS_MAX_COPY_SIZE_BYTES}
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
      - WEBSERVER_ANNOUNCEMENTS=${WEBSERVER_ANNOUNCEMENTS}
    deploy:
      labels:
        # ssl header necessary so that socket.io upgrades correctly from polling to websocket mode. the middleware must be attached to the right connection.
        # NOTE: traefik does not like - in the sslheader middleware, so we override it here
        # NOTE: in deploy mode with SSL they must be set to https!
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_sslheader.headers.customrequestheaders.X-Forwarded-Proto=https
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.service=${SWARM_STACK_NAME}_webserver
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.rule=PathPrefix(`/dev/`)
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.priority=2
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_webserver_swagger_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_swagger.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_webserver_swagger_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      update_config: &webserver_update_config
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy: &webserver_restart_policy
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      replicas: 3
      placement:
        constraints:
          - node.labels.simcore==true
      resources: &webserver_resources
        reservations:
          cpus: "0.1"
          memory: "512M"
        limits:
          cpus: "4"
          memory: "2G"
    extra_hosts: []

  wb-api-server:
    networks:
      - monitored
    deploy:
      update_config:
        <<: *webserver_update_config
      restart_policy:
        <<: *webserver_restart_policy
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        <<: *webserver_resources
    extra_hosts: []


  wb-db-event-listener:
    hostname: "{{.Service.Name}}"
    environment:
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
    networks:
      - default
    deploy:
      # NOTE: https://github.com/ITISFoundation/osparc-simcore/pull/4286
      # NOTE: this MUSTN'T change, or weird things might happen
      # this will stay until all legacy dynamic services are gone.
      replicas: 1
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore == true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "0.5"
          memory: "512M"

  wb-garbage-collector:
    environment:
      - WEBSERVER_LOGLEVEL=${WEBSERVER_LOGLEVEL}
    networks:
      - default
      - interactive_services_subnet
    hostname: "{{.Service.Name}}"
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.role==manager
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1.0"
          memory: "512M"

  storage:
    environment:
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - STORAGE_DEFAULT_PRESIGNED_LINK_EXPIRATION_SECONDS=${STORAGE_DEFAULT_PRESIGNED_LINK_EXPIRATION_SECONDS}
      - STORAGE_CLEANER_INTERVAL_S=${STORAGE_CLEANER_INTERVAL_S}
    networks:
      - monitored
    deploy:
      labels:
        # internal traefik
        - traefik.enable=true
        - traefik.docker.network=${SWARM_STACK_NAME}_default
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.rule=${DEPLOYMENT_FQDNS_CAPTURE_STORAGE}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.entrypoints=http
        - traefik.http.services.${SWARM_STACK_NAME}_storage.loadbalancer.server.port=8080
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_storage_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        - traefik.http.routers.${SWARM_STACK_NAME}_storage.middlewares=${SWARM_STACK_NAME_NO_HYPHEN}_storage_auth, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          memory: "3G"

  director:
    # Certificate necessary for local deploiement only
    #secrets:
    #- source: rootca.crt
    #target: /usr/local/share/ca-certificates/osparc.crt
    environment:
      - SIMCORE_SERVICES_NETWORK_NAME=${SWARM_STACK_NAME}_interactive_services_subnet
      - REGISTRY_SSL=${REGISTRY_SSL}
      # needed to pass the self-signed certificate to the spawned services
      #- DIRECTOR_SELF_SIGNED_SSL_FILENAME=/usr/local/share/ca-certificates/osparc.crt
      # - DIRECTOR_SELF_SIGNED_SSL_SECRET_ID=some_id
      #- DIRECTOR_SELF_SIGNED_SSL_SECRET_NAME=rootca.crt
      #- SSL_CERT_FILE=/usr/local/share/ca-certificates/osparc.crt
    networks:
      - monitored
    deploy:
      replicas: ${SIMCORE_DIRECTOR_V0_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "0.5"
          memory: "1G"

  director-v2:
    environment:
      - SIMCORE_SERVICES_NETWORK_NAME=${SWARM_STACK_NAME}_interactive_services_subnet
      - REGISTRY_SSL=${REGISTRY_SSL}
      - DIRECTOR_V2_DEV_FEATURES_ENABLED=${DIRECTOR_V2_DEV_FEATURES_ENABLED}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_SECURE=${S3_SECURE}
      - R_CLONE_PROVIDER=${R_CLONE_PROVIDER}
      - DYNAMIC_SIDECAR_LOG_LEVEL=${DYNAMIC_SIDECAR_LOG_LEVEL}
      - DIRECTOR_V2_LOGLEVEL=${DIRECTOR_V2_LOGLEVEL}
      # needed to pass the self-signed certificate to the spawned services
      #- DIRECTOR_SELF_SIGNED_SSL_FILENAME=/usr/local/share/ca-certificates/osparc.crt
      # - DIRECTOR_SELF_SIGNED_SSL_SECRET_ID=some_id
      #- DIRECTOR_SELF_SIGNED_SSL_SECRET_NAME=rootca.crt
      #- SSL_CERT_FILE=/usr/local/share/ca-certificates/osparc.crt
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: stop-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          memory: "1G"

  dask-sidecar:
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.dasksidecar==true
      resources:
        reservations:
          cpus: "0.1"
          memory: "256M"
        limits:
          cpus: "1"
          # memory: "16G"  # YH & SAN --> we should not limit dask sidecars | Jan 29 2024

  dask-scheduler:
    networks:
      - public
      - monitored
    deploy:
      replicas: ${SIMCORE_DASK_SCHEDULER_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      labels:
        - traefik.enable=true
        - traefik.docker.network=${PUBLIC_NETWORK}
        - traefik.http.services.${PREFIX_STACK_NAME}_dask_scheduler.loadbalancer.server.port=8787
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/${PREFIX_STACK_NAME}_dask`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.tls=true
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_dask_scheduler_replace_regex.replacepathregex.regex=^/${PREFIX_STACK_NAME}_dask/(.*)$$
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_dask_scheduler_replace_regex.replacepathregex.replacement=/$${1}
        - traefik.http.routers.${PREFIX_STACK_NAME}_dask_scheduler.middlewares=${PREFIX_STACK_NAME}_dask_scheduler_replace_regex@swarm, ops_gzip@swarm, ops_auth@swarm
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 128M
          cpus: '0.1'

  datcore-adapter:
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.2'
        reservations:
          memory: 128M
          cpus: '0.1'

  efs-guardian:
    hostname: "{{.Service.Name}}"
    deploy:
      replicas: ${SIMCORE_EFS_GUARDIAN_REPLICAS}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

  migration:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 16M
          cpus: '0.1'
      placement:
        constraints:
          - node.labels.simcore==true

  rabbit:
    networks:
      - monitored
      - public
    volumes:
      - rabbit_data:/var/lib/rabbitmq
    deploy:
      labels:
        - traefik.enable=true
        - traefik.docker.network=${PUBLIC_NETWORK}
        - traefik.http.services.${PREFIX_STACK_NAME}_rabbit.loadbalancer.server.port=15672
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit.rule=Host(`${MONITORING_DOMAIN}`) && PathPrefix(`/${PREFIX_STACK_NAME}_rabbit`)
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit.entrypoints=https
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit.tls=true
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_rabbit_replace_regex.replacepathregex.regex=^/${PREFIX_STACK_NAME}_rabbit/(.*)$$
        - traefik.http.middlewares.${PREFIX_STACK_NAME}_rabbit_replace_regex.replacepathregex.replacement=/$${1}
        - traefik.http.routers.${PREFIX_STACK_NAME}_rabbit.middlewares=${PREFIX_STACK_NAME}_rabbit_replace_regex@swarm, ops_gzip@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.rabbit==true
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 256M
          cpus: '0.1'

  redis:
    networks:
      - monitored
    deploy:
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.redis==true
      resources:
        limits:
          memory: 1G
          cpus: '1.000'
        reservations:
          memory: 32M
          cpus: '0.1'

  resource-usage-tracker:
    networks:
      - monitored
      - public
    hostname: "{{.Service.Name}}"
    deploy:
      # NOTE: https://github.com/ITISFoundation/osparc-simcore/pull/4286
      # NOTE: this MUSTN'T change, or weird things might happen
      # this will stay until all legacy dynamic services are gone.
      replicas: 1
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

  postgres:
    networks:
      - monitored
      - public
    deploy:
      labels:
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.docker.network=${PUBLIC_NETWORK}
        - traefik.tcp.services.${SWARM_STACK_NAME}_postgres.loadBalancer.server.port=5432
        - traefik.tcp.routers.postgres.service=${SWARM_STACK_NAME}_postgres
        - traefik.tcp.routers.postgres.entrypoints=postgres
        - traefik.tcp.routers.postgres.tls=false
        - traefik.tcp.routers.postgres.rule=HostSNI(`*`)
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.role==manager
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 1.5G
          # cpus: '0.1'  # tmp fix due to lack of resources on master | YH Dec 2023

  traefik:
    networks:
      - monitored
      - public
    deploy:
      replicas: 2
      labels:
        # Prometheus
        - prometheus-job=traefik_simcore
        - prometheus-port=8082
        # external traefik
        - traefik.enable=true
        - traefik.docker.network=${PUBLIC_NETWORK}
        # oSparc web
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_http.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.service=${SWARM_STACK_NAME}_simcore_http
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.rule=((${DEPLOYMENT_FQDNS_CAPTURE_TRAEFIK_RULE_CATCHALL}) && PathPrefix(`/`)) || ( (PathPrefix(`/dashboard`) || PathPrefix(`/api`) ) && Host(`traefikdashboard.${MACHINE_FQDN}`))
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_http.priority=1 # Lowest possible priority, maintenance page takes priority "2" (higher, maintenance page has precedent) if it is up
        # oSparc publicAPI
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.rule=(${DEPLOYMENT_API_DOMAIN_CAPTURE_TRAEFIK_RULE}) && PathPrefix(`/`)
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.entrypoints=https
        - traefik.http.services.${SWARM_STACK_NAME}_simcore_api.loadbalancer.server.port=10081
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.middlewares=ops_gzip@swarm, ops_ratelimit@swarm
        - traefik.http.routers.${SWARM_STACK_NAME}_simcore_api.service=${SWARM_STACK_NAME}_simcore_api
        # oSparc non rate limited webAPI for testing
        - traefik.http.services.${SWARM_STACK_NAME}_testing_simcore_http.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.service=${SWARM_STACK_NAME}_testing_simcore_http
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.rule=(${DEPLOYMENT_FQDNS_TESTING_CAPTURE_TRAEFIK_RULE})
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_http.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_auth@swarm, ops_whitelist_ips@swarm
        # oSparc non rate limited publicAPI for testing
        - traefik.http.services.${SWARM_STACK_NAME}_testing_simcore_api.loadbalancer.server.port=10081
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.service=${SWARM_STACK_NAME}_testing_simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.rule=(${DEPLOYMENT_API_DOMAIN_TESTING_CAPTURE_TRAEFIK_RULE})
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.entrypoints=https
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.tls=true
        - traefik.http.routers.${SWARM_STACK_NAME}_testing_simcore_api.middlewares=ops_gzip@swarm, ops_sslheader@swarm, ops_auth@swarm, ops_whitelist_ips@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.traefik==true
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 128M
          cpus: '0.1'
  traefik_api:
    # NOTE: this is a trick to allow to access the internal traefik REST API
    # A comment
    # list router like so: curl https://domain/api/http/routers | jq
    image: busybox:1.35.0
    command: sleep 900000d
    networks:
      - default
    deploy:
      labels:
        # route to internal traefik
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # traefik UI
        - traefik.enable=true
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.service=api@internal
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.rule=(PathPrefix(`/dashboard`) || PathPrefix(`/api`) ) && Host(`traefikdashboard.${MACHINE_FQDN}`)
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.priority=2
        - traefik.http.routers.${SWARM_STACK_NAME}_traefik_api.middlewares=${SWARM_STACK_NAME}_auth@swarm, ${SWARM_STACK_NAME}_whitelist_ips@swarm
        - traefik.http.services.${SWARM_STACK_NAME}_traefik_api.loadbalancer.server.port=8080
        # Middlewares
        # basic authentication
        - traefik.http.middlewares.${SWARM_STACK_NAME}_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        # OPS IP Whitelist
        - traefik.http.middlewares.${SWARM_STACK_NAME}_whitelist_ips.ipallowlist.sourcerange=${TRAEFIK_IPWHITELIST_SOURCERANGE}
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.traefik==true
      resources:
        limits:
          memory: 16M
          cpus: '0.1'
        reservations:
          memory: 8M
          cpus: '0.1'
  whoami:
    image: "containous/whoami:v1.5.0"
    networks:
      - default
    # NOTE: this service allows better understanding of how the host gets forwarded inside the simcore stack
    deploy:
      labels:
        # internal traefik
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # basic authentication
        - traefik.http.middlewares.${SWARM_STACK_NAME}_auth.basicauth.users=${TRAEFIK_USER}:${TRAEFIK_PASSWORD}
        # whoami
        - traefik.enable=true
        - traefik.http.services.${SWARM_STACK_NAME}_whoami.loadbalancer.server.port=80
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.rule=PathPrefix(`/whoami`)
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.priority=2
        - traefik.http.routers.${SWARM_STACK_NAME}_whoami.middlewares=${SWARM_STACK_NAME}_auth@swarm,${SWARM_STACK_NAME}_gzip@swarm
      update_config:
        parallelism: 2
        order: start-first
        failure_action: continue
        delay: 10s
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.labels.ops==true
      resources:
        limits:
          memory: 16M
          cpus: '0.1'
        reservations:
          memory: 8M
          cpus: '0.1'
  payments:
    deploy:
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.1'
    networks:
      - appmotion
      - monitored

  dynamic-schdlr:
    networks:
      - monitored
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.labels.simcore==true
      resources:
        limits:
          memory: 500M
          cpus: '1.000'
        reservations:
          memory: 50M
          cpus: '0.1'

volumes:
  rabbit_data:
    name: ${SWARM_STACK_NAME}_rabbit_data
networks:
  public:
    external: true
    name: ${OPS_PUBLIC_NETWORK}
  monitored:
    external: true
    name: ${OPS_MONITORED_NETWORK}
  appmotion:
    external: true
    name: ${OPS_APPMOTION_NETWORK}
  storage_subnet:
    attachable: true
    name: ${SWARM_STACK_NAME}_storage_subnet
  computational_services_subnet:
    name: ${SWARM_STACK_NAME}_computational_services_subnet
    attachable: true
  interactive_services_subnet:
    name: ${SWARM_STACK_NAME}_interactive_services_subnet
    external: true
